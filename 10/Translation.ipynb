{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 다양한 RNN의 구성을 알아보기\n",
    "2. 인코더와 디코더 구조의 필요성 이해하기\n",
    "3. 교사 강요(teacher forcing)의 원리 알기\n",
    "4. 훈련 단계와 추론 단계(inference)의 차이 알기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계 번역 이야기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data/MT.png' height = '50%' width = '50%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 규칙 기반 -> 통계적 기계 번역 -> 신경망 기계 번역\n",
    "* seq2seq : 초창기 신경망 기계번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스 처리하는 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data/RNN.jpg' height = '50%' width = '50%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "번역기는 첫번재 many to many 형식으로 만들어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data/seq2seq_1.jpg' height = '50%' width = '50%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2개의 RNN 아키텍쳐를 연결한 구조.\n",
    "* 입력 문장을 받는 RNN을 인코더\n",
    "* 두번째 RNN을 디코터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data/EncoderDecoder_1.png' height = '70%' width = '70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoder : Feature extractor 역할 - 어떤 데이터를 해석하기 위해 feature vector z를 만들어냅니다.\n",
    "* Decoder : Feature z로부터 정보를 복원하여 다른 데이터를 재생성하는 역할."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* seq2seq 모델은 이 Encoder와 Decoder 둘 다 RNN 인 경우.\n",
    "* feature vector : RNN이 문장을 해석해 만든 hidden state vector\n",
    "* 문장 X를 z 라는 hidden state로 해석 후 z를 다시 언어 문장 Y롤 재생성\n",
    "* 인코더에서 필요한 것은 인코더의 마지막 time step의 hidden state, 이를 두번째 RNN인 Decoder에게 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 디코더는 인코더의 마지막 time step의 hidden state를 받아서 자신의 초기 hidden state로 하고 출력 문장을 생성.\n",
    "* 여기서 특수 문자를 사용해서 출력 문장의 시작과 끝을 알려주기.\n",
    "* 위 위 그림에서 GO, EOS 가 시작과 끝, 경우에 따라 SOS, EOS 라고도 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장 생성기(Text Generator) : 언어 모델을 구현한 것\n",
    "* 언어 모델 : n-1개의 단어 시퀀스 $w_1, ..., w_{n-1}$ 가 주어질때 n 번째 단어로 무엇이 올지 예측하는 확률 모델\n",
    "* 파라미터 $\\theta$를 모델링하는 언어 모델을 다음과 같이 표현\n",
    "$$ P(w_n|w_1, ..., w_{n-1};\\theta)$$\n",
    "* 문장 생성기는 어떤 말을 만들고 싶은지 제어할 수 없다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 상황에 맞게 제어할 수 있게 언어모델을 확장하여 조건적 언어모델을 만듬.\n",
    "$$ P(w_n|w_1, ..., w_{n-1},c;\\theta)$$\n",
    "* c : 아무 문장이나 만들지 말고 c에 맞는 문장을 만들어라.\n",
    "* 인코더가 문장 X를 해석해서 *c* 를 만들고 *c* 를 문장생성기인 디코더에 입력으로 넣어주는 모델이 seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교사 강요(teacher forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data/Teacher_forcing.png' height = '10%' width = '30%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 과정에서 이전 time step이 잘못 예측하면 이번 예측도 잘못될 수 있고 이러면 훈련 시간이 엄청 길어진다.\n",
    "* 이를 막기위해 이전 time step의 실제 값을 입력 값으로 사용하게 함.\n",
    "* 이를 Teacher Forcing이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 수준 VS 문자 수준"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word level VS Character level\n",
    "* time step의 입출력 단위\n",
    "* 단어 집합은 엄청 많아지는 반면 문자는 알파벳 전부기 때문에 실제 구현 자체는 문자 수준이 더 편하다.\n",
    "* 띄어쓰기 또는 많은 변종이 있는 언어는 문자 수준이 좋다.\n",
    "* 하지만 그만큼 단어를 문자로 쪼개면서 데이터를 손실시키는것이기 때문에 충분한 데이터가 없다면 단어모델도 더 품질이 떨어진다.\n",
    "* 최신 자연어처리는 subword를 기반으로 이루어진다.\n",
    "* 우리는 문자 수준을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번역기를 만들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules(library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:14:18.908392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:18.978654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:18.978900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2467131201188759317\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6992625664\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 813260309171879551\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:14:18.981449: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 19:14:18.982822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:18.983142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:18.983269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:19.756773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:19.757014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:19.757127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:19.757230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 6668 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 194513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117054</th>\n",
       "      <td>Mary is a very attractive girl.</td>\n",
       "      <td>Mary est une fille très attirante.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127775</th>\n",
       "      <td>I don't know how to speak French.</td>\n",
       "      <td>Je ne sais pas parler français.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80472</th>\n",
       "      <td>Let's go outside and play.</td>\n",
       "      <td>Sortons dehors jouer.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50925</th>\n",
       "      <td>Maybe I'll buy a bike.</td>\n",
       "      <td>J'achèterai peut-être un vélo.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118576</th>\n",
       "      <td>Tom is at the neighbor's house.</td>\n",
       "      <td>Tom est chez le voisin.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      eng                                 fra  \\\n",
       "117054    Mary is a very attractive girl.  Mary est une fille très attirante.   \n",
       "127775  I don't know how to speak French.     Je ne sais pas parler français.   \n",
       "80472          Let's go outside and play.               Sortons dehors jouer.   \n",
       "50925              Maybe I'll buy a bike.      J'achèterai peut-être un vélo.   \n",
       "118576    Tom is at the neighbor's house.             Tom est chez le voisin.   \n",
       "\n",
       "                                                       cc  \n",
       "117054  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "127775  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "80472   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "50925   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "118576  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC 제거 및 5만개만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>How tall is he?</td>\n",
       "      <td>Quelle taille fait-il ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46156</th>\n",
       "      <td>What's Tom's address?</td>\n",
       "      <td>Quelle est l'adresse de Tom ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27160</th>\n",
       "      <td>What is your plan?</td>\n",
       "      <td>Quel est ton plan ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49002</th>\n",
       "      <td>I find you attractive.</td>\n",
       "      <td>Je te trouve attirante.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33223</th>\n",
       "      <td>Who can prevent it?</td>\n",
       "      <td>Qui peut l'empêcher ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eng                            fra\n",
       "10185         How tall is he?        Quelle taille fait-il ?\n",
       "46156   What's Tom's address?  Quelle est l'adresse de Tom ?\n",
       "27160      What is your plan?            Quel est ton plan ?\n",
       "49002  I find you attractive.        Je te trouve attirante.\n",
       "33223     Who can prevent it?          Qui peut l'empêcher ?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:50000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = lambda x : [0] + x\n",
    "x= [5]\n",
    "func(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>Don't worry.</td>\n",
       "      <td>\\t Ne vous en faites pas. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38388</th>\n",
       "      <td>Tom can't even read.</td>\n",
       "      <td>\\t Tom ne peut même pas lire. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>I am a professor.</td>\n",
       "      <td>\\t Je suis professeur. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>I did OK.</td>\n",
       "      <td>\\t Je m'en suis bien sorti. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38802</th>\n",
       "      <td>Tom was never happy.</td>\n",
       "      <td>\\t Tom n'était jamais heureux. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                                fra\n",
       "2895           Don't worry.       \\t Ne vous en faites pas. \\n\n",
       "38388  Tom can't even read.   \\t Tom ne peut même pas lire. \\n\n",
       "18244     I am a professor.          \\t Je suis professeur. \\n\n",
       "598               I did OK.     \\t Je m'en suis bien sorti. \\n\n",
       "38802  Tom was never happy.  \\t Tom n'était jamais heureux. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어장 및 정수 인코딩 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* char_level = True : 문자단위로 Tokenizer 생성\n",
    "* eng, fra의 각행에 토큰화를 수행\n",
    "* 단어를 숫자값 인덱스로 변환하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=True) \n",
    "eng_tokenizer.fit_on_texts(lines.eng)\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 1, 19, 5, 1, 31, 1, 11],\n",
       " [10, 1, 15, 5, 12, 16, 29, 2, 14, 1, 11],\n",
       " [10, 1, 26, 9, 8, 28, 2, 1, 31, 1, 11]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)\n",
    "fra_tokenizer.fit_on_texts(lines.fra)\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단어장 크기를 변수로 저장. 0번 토큰을 생각해서 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 53\n",
      "프랑스어 단어장의 크기 : 73\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최대 길이 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 22\n",
      "프랑스어 시퀀스의 최대 길이 76\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n",
      "영어 단어장의 크기 : 53\n",
      "프랑스어 단어장의 크기 : 73\n",
      "영어 시퀀스의 최대 길이 22\n",
      "프랑스어 시퀀스의 최대 길이 76\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더와 디코더의 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인코더 입력인 영어와 달리 프랑스 시퀀스는 2가지 버전으로 나누어 준비\n",
    "* 하나의 디코더 출력과 비교해야 할 정답 데이터로 사용할 원래 목적\n",
    "* 나머지 하나는 teacher forcing 용(디코더 입력용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 디코더 입력은 <'eos'>가 필요없고 출력과 비교할 시퀀스는 <'sos'>가 필요없다.\n",
    "* A를 B로 번역할때 훈련과정에서 디코더가 <'sos'>A 를 받아서 B<'eos'> 를 예측하도록 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 1, 19, 5, 1, 31, 1], [10, 1, 15, 5, 12, 16, 29, 2, 14, 1], [10, 1, 26, 9, 8, 28, 2, 1, 31, 1]]\n",
      "[[1, 19, 5, 1, 31, 1, 11], [1, 15, 5, 12, 16, 29, 2, 14, 1, 11], [1, 26, 9, 8, 28, 2, 1, 31, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 22)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 76)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 76)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역시 0으로 패딩이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 정수에 따른 벡터화 방법으로 one-hot encoding 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 샘플의 크기 = 샘플의 수 * 샘플의 크기 * 단어장의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 22, 53)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 76, 73)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 검증을 위해 5만 건 중에 3천건만 검증 데이터로 삼고, 나머지를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (50000, 22, 53)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (50000, 76, 73)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (50000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더 설계 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSTM 설계\n",
    "* LSTM 은 hidden state, cell state 2개 존재\n",
    "* Encoder LSTM 이 마지막 time step의 hidden state, cell state 를 Decoder LSTM 의 첫 번째 hidden state, cell state 로 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 텐서 생성.\n",
    "* hidden size가 256인 인코더의 LSTM 셀 생성, return_state = True 를 통해 hidden state, cell state 를 return\n",
    "* 디코더로 전달할 마지막 time step의 hidden state, cell state를 리턴. \n",
    "* hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:14:23.746800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:23.746989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:23.747094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:23.747236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:23.747366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 19:14:23.747467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6668 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더 설계 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 텐서 생성.\n",
    "* hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "* decoder_outputs는 모든 time step의 hidden state\n",
    "* initial_state 를 통해 초기 상태를 지정가능(이전의 encoder_states 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dense layer 에 softmax로 단어장에서 1개만 선택(문자 기준이므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하나의 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인코더와 디코더를 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 53)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 73)]   0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        317440      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  337920      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 73)     18761       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 674,121\n",
      "Trainable params: 674,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:14:24.647095: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1043024000 exceeds 10% of free system memory.\n",
      "2022-08-22 19:14:25.489727: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1043024000 exceeds 10% of free system memory.\n",
      "2022-08-22 19:14:26.387027: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1043024000 exceeds 10% of free system memory.\n",
      "2022-08-22 19:14:26.919331: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1043024000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:14:31.093168: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 11s 17ms/step - loss: 0.8860 - val_loss: 0.7733\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.5443 - val_loss: 0.6348\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.4514 - val_loss: 0.5616\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3971 - val_loss: 0.5122\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.3602 - val_loss: 0.4685\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3339 - val_loss: 0.4433\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3142 - val_loss: 0.4277\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2983 - val_loss: 0.4097\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2851 - val_loss: 0.3983\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.2743 - val_loss: 0.3915\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.2654 - val_loss: 0.3862\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.2565 - val_loss: 0.3777\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2489 - val_loss: 0.3814\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 7s 18ms/step - loss: 0.2420 - val_loss: 0.3739\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.2357 - val_loss: 0.3698\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2299 - val_loss: 0.3670\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.2249 - val_loss: 0.3661\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2204 - val_loss: 0.3649\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2157 - val_loss: 0.3634\n",
      "Epoch 20/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2113 - val_loss: 0.3599\n",
      "Epoch 21/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2070 - val_loss: 0.3584\n",
      "Epoch 22/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.2032 - val_loss: 0.3601\n",
      "Epoch 23/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1994 - val_loss: 0.3651\n",
      "Epoch 24/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1959 - val_loss: 0.3650\n",
      "Epoch 25/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.1925 - val_loss: 0.3612\n",
      "Epoch 26/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1892 - val_loss: 0.3658\n",
      "Epoch 27/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1862 - val_loss: 0.3686\n",
      "Epoch 28/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1831 - val_loss: 0.3694\n",
      "Epoch 29/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1804 - val_loss: 0.3676\n",
      "Epoch 30/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1775 - val_loss: 0.3671\n",
      "Epoch 31/50\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.1749 - val_loss: 0.3690\n",
      "Epoch 32/50\n",
      "368/368 [==============================] - 7s 18ms/step - loss: 0.1724 - val_loss: 0.3735\n",
      "Epoch 33/50\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.1699 - val_loss: 0.3774\n",
      "Epoch 34/50\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.1675 - val_loss: 0.3813\n",
      "Epoch 35/50\n",
      "368/368 [==============================] - 6s 18ms/step - loss: 0.1653 - val_loss: 0.3899\n",
      "Epoch 36/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1630 - val_loss: 0.3826\n",
      "Epoch 37/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1609 - val_loss: 0.3900\n",
      "Epoch 38/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1588 - val_loss: 0.3875\n",
      "Epoch 39/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1568 - val_loss: 0.3916\n",
      "Epoch 40/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1548 - val_loss: 0.3950\n",
      "Epoch 41/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1529 - val_loss: 0.3944\n",
      "Epoch 42/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1510 - val_loss: 0.3970\n",
      "Epoch 43/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1492 - val_loss: 0.4039\n",
      "Epoch 44/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1475 - val_loss: 0.4047\n",
      "Epoch 45/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1457 - val_loss: 0.4083\n",
      "Epoch 46/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1442 - val_loss: 0.4125\n",
      "Epoch 47/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1426 - val_loss: 0.4156\n",
      "Epoch 48/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1410 - val_loss: 0.4140\n",
      "Epoch 49/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1394 - val_loss: 0.4170\n",
      "Epoch 50/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.1380 - val_loss: 0.4204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc89e3ff9a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 디코더의 동작 순서\n",
    "1. 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
    "2. 토큰인 '\\t'를 디코더에 입력한다.\n",
    "3. 이전 time step의 출력층의 예측 결과를 현재 time step의 입력으로 한다.\n",
    "4. 3을 반복하다가 토큰인 '\\n'가 예측되면 이를 중단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 53)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 256),             317440    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317,440\n",
      "Trainable params: 317,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이전 time step의 hidden state를 저장하는 텐서\n",
    "* 이전 time step의 cell state를 저장하는 텐서\n",
    "* 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "\n",
    "* decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "* 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "* 현재 time step의 hidden state와 cell state를 하나의 변수에 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 디코더의 출력층 재설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 73)]   0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  337920      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'input_3[0][0]',                \n",
      "                                 (None, 256)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 73)     18761       ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 356,681\n",
      "Trainable params: 356,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예측과정을 위한 함수 decode_sequence()를 구현합니다.\n",
    "* 입력은 번역하고자 하는 문장의 정수 시퀀스입니다.\n",
    "* 내부에는 인코더를 구현한 encoder_model이 있어서 이 모델에 번역하고자하는 문장의 정수 시퀀스인 'input_seq'를 입력하면\n",
    "* encoder_model의 마지막 시점의 hidden state를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "    target_seq[0, 0, fra2idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 구현한 함수를 임의의 인덱스의 번역할 문장 샘플을 넣어서 테스트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Hi.\n",
      "정답 문장:  Salut ! \n",
      "번역기가 번역한 문장:  salut ! \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장:  Salut ! \n",
      "번역기가 번역한 문장:  aide-toi ! \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Hop in.\n",
      "정답 문장:  Montez. \n",
      "번역기가 번역한 문장:  monte. \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Help me!\n",
      "정답 문장:  Aide-moi ! \n",
      "번역기가 번역한 문장:  aide-moi ! \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Humor Tom.\n",
      "정답 문장:  Mettez Tom de bonne humeur. \n",
      "번역기가 번역한 문장:  en avant m'instouche. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3d548dbc07dac0e24bbfeb6e932dc9e9a9d93b0bdd3d2fd0655f4be29fd0580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
